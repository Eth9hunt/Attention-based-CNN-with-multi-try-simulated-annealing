{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def attention_block(inputs, skip_connection):\n",
        "\n",
        "    # Compute channels for skip and output tensor\n",
        "    channels = K.int_shape(skip_connection)[-1]\n",
        "    filters = channels // 4\n",
        "\n",
        "    # Compute attention mechanism\n",
        "    x = Conv2D(filters, kernel_size=3, padding='same')(inputs)\n",
        "    skip = Conv2D(filters, kernel_size=3, padding='same')(skip_connection)\n",
        "    x = Activation('leaky_relu')(x + skip)\n",
        "    x = Conv2D(1, kernel_size=3, padding='same')(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    x = Multiply()([inputs, x])\n",
        "    return x\n",
        "\n",
        "def attention_unet(input_shape, n_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv5 = Conv2D(1024, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = Conv2D(512, 2, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(drop5))\n",
        "    att6 = attention_block(conv4, up6)\n",
        "    merge6 = concatenate([att6, up6], axis=3)\n",
        "    conv6 = Conv2D(512, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
        "    att7 = attention_block(conv3, up7)\n",
        "    merge7 = concatenate([att7, up7], axis=3)\n",
        "    conv7 = Conv2D(256, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
        "    att8 = attention_block(conv2, up8)\n",
        "    merge8 = concatenate([att8, up8], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv8))\n",
        "    att9 = attention_block(conv1, up9)\n",
        "    merge9 = concatenate([att9, up9], axis=3)\n",
        "    conv9 = Conv2D(64, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='leaky_relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(n_classes, 1, activation='softmax')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv9)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "L66WIwAhC96O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJdlWHmwE1F4",
        "outputId": "58ef0e8a-8d5a-47ef-a149-9f9e20aa5ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = attention_unet(input_shape=(512, 512, 1), n_classes=1)"
      ],
      "metadata": {
        "id": "HBUan9F3DIEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "\n",
        "  numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "  denominator = tf.reduce_sum(y_true + y_pred)\n",
        "  return numerator / (denominator + tf.keras.backend.epsilon())\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "  return 1 - dice_coefficient(y_true, y_pred)"
      ],
      "metadata": {
        "id": "Ik8BSK8G9Mo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness(x_train, y_train, model):\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=dice_loss,\n",
        "  metrics=[dice_coefficient])\n",
        "  history = model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "  return history.history['val_dice_coefficient'][-1]"
      ],
      "metadata": {
        "id": "YVmbD38V9tep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mtsa(x_train, y_train, model, num_tries, t_init, t_min, alpha):\n",
        "\n",
        "  n = x_train.shape[0]\n",
        "  d = x_train.shape[1:]\n",
        "  x_best = np.random.rand(*d)\n",
        "  y_best = np.random.rand(*d)\n",
        "  f_best = fitness(x_train, y_train, model)\n",
        "  for i in range(num_tries):\n",
        "    t = t_init\n",
        "    x_curr = np.random.rand(*d)\n",
        "    y_curr = np.random.rand(*d)\n",
        "    f_curr = fitness(x_train, y_train, model)\n",
        "    while t > t_min:\n",
        "\n",
        "      for j in range(10):\n",
        "\n",
        "        x_prop = x_curr + np.random.normal(size=d, scale=0.1)\n",
        "        y_prop = y_curr + np.random.normal(size=d, scale=0.1)\n",
        "        f_prop = fitness(x_train, y_train, model)\n",
        "        delta_f = f_prop - f_curr\n",
        "        if delta_f < 0 or np.exp(-delta_f/t) > np.random.rand():\n",
        "          x_curr = x_prop\n",
        "          y_curr = y_prop\n",
        "          f_curr = f_prop\n",
        "        if f_curr < f_best:\n",
        "          x_best = x_curr\n",
        "          y_best = y_prop\n",
        "          f_best = f_curr\n",
        "          t *= alpha\n",
        "  return x_best, y_best, f_best"
      ],
      "metadata": {
        "id": "PYCEooLs90AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45plJSLT9_m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#EDIT HERE##############################\n",
        "datafolder='/content/drive/MyDrive/11 April 2023/processeddata/'\n",
        "weightsfolder='/content/drive/MyDrive/11 April 2023/modelweights'\n",
        "noduleimages=np.load(\"/content/drive/MyDrive/10_april_2023/new_500/nod_im_1.npy\")\n",
        "nodulemasks=np.load(\"/content/drive/MyDrive/10_april_2023/new_500/nod_mask_1.npy\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jfl4JFzA_kmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noduleimages=noduleimages.reshape(noduleimages.shape[0],512,512,1)\n",
        "nodulemasks=nodulemasks.reshape(nodulemasks.shape[0],512,512,1)\n",
        "imagestrain, imagestest, maskstrain, maskstest = train_test_split(noduleimages,nodulemasks,test_size=.20)\n",
        "\n",
        "####\n",
        "maskstrain2 = maskstrain.astype(np.float32)\n",
        "maskstest2 = maskstest.astype(np.float32)"
      ],
      "metadata": {
        "id": "dlmG_Dtp_-OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=imagestrain\n",
        "y_train=maskstrain2\n",
        "\n",
        "x_val=imagestest\n",
        "y_val=maskstest2"
      ],
      "metadata": {
        "id": "Hx7hiKthCp1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize images between 0 and 1\n",
        "\n",
        "xx_train=(x_train-np.min(x_train))/(np.max(x_train)-np.min(x_train))\n",
        "xx_val=(x_val-np.min(x_val))/(np.max(x_val)-np.min(x_val))\n",
        "\n",
        "\n",
        "#conver binary images mask into real values of nodule pixels\n",
        "\n",
        "yy_train=x_train*y_train\n",
        "yy_val=x_val*y_val"
      ],
      "metadata": {
        "id": "5DygTgQbB1yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x_best, y_best, f_best = mtsa(xx_train, yy_train, model, num_tries=10, t_init=10.0, t_min=0.1, alpha=0.99)\n",
        "\n"
      ],
      "metadata": {
        "id": "dGrXv5Yd-RCW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "loss=dice_loss,\n",
        "metrics=[dice_coefficient])\n"
      ],
      "metadata": {
        "id": "sv1Xs2ky_lg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "id": "rMH_eiZn_qlw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}